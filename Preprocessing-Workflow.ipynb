{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Workflow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üéØ This exercise will guide you through the preprocessing workflow. Step by step, feature by feature, you will investigate the dataset and take preprocessing decisions accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üå§ We stored the `ML_Houses_dataset.csv` [here](https://wagon-public-datasets.s3.amazonaws.com/Machine%20Learning%20Datasets/ML_Houses_dataset.csv) in the cloud.\n",
    "\n",
    "üëá Run the code down below to load the dataset and features you will be working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>KitchenAbvGr</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>RoofSurface</th>\n",
       "      <th>GarageFinish</th>\n",
       "      <th>CentralAir</th>\n",
       "      <th>ChimneyStyle</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1710</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>Y</td>\n",
       "      <td>bricks</td>\n",
       "      <td>2</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1262</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>874.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>Y</td>\n",
       "      <td>bricks</td>\n",
       "      <td>5</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1786</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1593.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>Y</td>\n",
       "      <td>castiron</td>\n",
       "      <td>9</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1717</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2566.0</td>\n",
       "      <td>Unf</td>\n",
       "      <td>Y</td>\n",
       "      <td>castiron</td>\n",
       "      <td>2</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2198</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3130.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>Y</td>\n",
       "      <td>bricks</td>\n",
       "      <td>12</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GrLivArea  BedroomAbvGr  KitchenAbvGr  OverallCond  RoofSurface  \\\n",
       "0       1710             3             1            5       1995.0   \n",
       "1       1262             3             1            8        874.0   \n",
       "2       1786             3             1            5       1593.0   \n",
       "3       1717             3             1            5       2566.0   \n",
       "4       2198             4             1            5       3130.0   \n",
       "\n",
       "  GarageFinish CentralAir ChimneyStyle  MoSold  SalePrice  \n",
       "0          RFn          Y       bricks       2     208500  \n",
       "1          RFn          Y       bricks       5     181500  \n",
       "2          RFn          Y     castiron       9     223500  \n",
       "3          Unf          Y     castiron       2     140000  \n",
       "4          RFn          Y       bricks      12     250000  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Loading the dataset\n",
    "url = \"https://wagon-public-datasets.s3.amazonaws.com/Machine%20Learning%20Datasets/ML_Houses_dataset.csv\"\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# Selecting some columns of interest\n",
    "selected_features = ['GrLivArea',\n",
    "                     'BedroomAbvGr',\n",
    "                     'KitchenAbvGr', \n",
    "                     'OverallCond',\n",
    "                     'RoofSurface',\n",
    "                     'GarageFinish',\n",
    "                     'CentralAir',\n",
    "                     'ChimneyStyle',\n",
    "                     'MoSold',\n",
    "                     'SalePrice']\n",
    "\n",
    "# Overwriting the \"data\" variable to keep only the columns of interest\n",
    "# Notice the .copy() to copy the values \n",
    "data = data[selected_features].copy()\n",
    "\n",
    "# Showing the first five rows\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìö Take the time to do a ***preliminary investigation*** of the features by reading the ***dataset description*** available [here](https://wagon-public-datasets.s3.amazonaws.com/Machine%20Learning%20Datasets/ML_Houses_dataset_description.txt). Make sure to refer to it throughout the day."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ÑπÔ∏è ***Duplicates in datasets cause data leakage.*** \n",
    "\n",
    "üëâ It is important to locate and remove duplicates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì How many duplicated rows are there in the dataset ‚ùì\n",
    "\n",
    "<i>Save your answer under variable name `duplicate_count`.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "duplicate_count = data.duplicated().sum()\n",
    "duplicate_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Remove the duplicates from the dataset. Overwite the dataframe `data`‚ùì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "data = data.drop_duplicates()\n",
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üß™ **Test your code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.10.6, pytest-7.1.3, pluggy-1.0.0 -- /home/ricorenzo/.pyenv/versions/lewagon/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/ricorenzo/code/renzorico/data-preprocessing-workflow/tests\n",
      "plugins: asyncio-0.19.0, anyio-3.6.2\n",
      "asyncio: mode=strict\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 2 items\n",
      "\n",
      "test_duplicates.py::TestDuplicates::test_dataset_length \u001b[32mPASSED\u001b[0m\u001b[32m           [ 50%]\u001b[0m\n",
      "test_duplicates.py::TestDuplicates::test_duplicate_count \u001b[32mPASSED\u001b[0m\u001b[32m          [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m2 passed\u001b[0m\u001b[32m in 0.32s\u001b[0m\u001b[32m ===============================\u001b[0m\n",
      "\n",
      "\n",
      "üíØ You can commit your code:\n",
      "\n",
      "\u001b[1;32mgit\u001b[39m add tests/duplicates.pickle\n",
      "\n",
      "\u001b[32mgit\u001b[39m commit -m \u001b[33m'Completed duplicates step'\u001b[39m\n",
      "\n",
      "\u001b[32mgit\u001b[39m push origin master\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('duplicates',\n",
    "                         duplicates = duplicate_count,\n",
    "                         dataset = data\n",
    ")\n",
    "\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master 44a443a] Completed duplicates step\n",
      " 1 file changed, 91 insertions(+), 147 deletions(-)\n",
      "ERROR: Repository not found.\n",
      "fatal: Could not read from remote repository.\n",
      "\n",
      "Please make sure you have the correct access rights\n",
      "and the repository exists.\n"
     ]
    }
   ],
   "source": [
    "!git add .\n",
    "\n",
    "!git commit -m 'Completed duplicates step'\n",
    "\n",
    "!git push origin master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) Missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Print the percentage of missing values for every column of the dataframe. ‚ùì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GrLivArea       0.000000\n",
       "BedroomAbvGr    0.000000\n",
       "KitchenAbvGr    0.000000\n",
       "OverallCond     0.000000\n",
       "CentralAir      0.000000\n",
       "ChimneyStyle    0.000000\n",
       "MoSold          0.000000\n",
       "SalePrice       0.000000\n",
       "RoofSurface     0.616438\n",
       "GarageFinish    5.547945\n",
       "dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "missing_values = data.isnull().sum().sort_values()/len(data)\n",
    "missing_values_percentage = missing_values * 100\n",
    "missing_values_percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `GarageFinish`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Questions** about `GarageFinish` ‚ùì\n",
    "\n",
    "Investigate the missing values in `GarageFinish`. Then, choose one of the following solutions:\n",
    "\n",
    "1. Drop the column entirely\n",
    "2. Impute the column median using `SimpleImputer` from Scikit-Learn\n",
    "3. Preserve the NaNs and replace them with meaningful values\n",
    "\n",
    "Make changes effective in the dataframe `data`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>üí° <i>Hint</i></summary>\n",
    "    \n",
    "‚ÑπÔ∏è According to the dataset description, the missing values in `GarageFinish` represent a house having no garage. They need to be encoded as such.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "data.GarageFinish.replace(np.nan, \"NoGarage\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `RoofSurface`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Questions** about `RoofSurface` ‚ùì\n",
    "\n",
    "Investigate the missing values in `RoofSurface`. Then, choose one of the following solutions:\n",
    "\n",
    "1. Drop the column entirely\n",
    "2. Impute the column median using sklearn's `SimpleImputer`\n",
    "3. Preserve the NaNs and replace them with meaningful values\n",
    "\n",
    "Make changes effective in the dataframe `data`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>üí° <i>Hint</i></summary>\n",
    "    \n",
    "‚ÑπÔ∏è `RoofSurface` has a few missing values that can be imputed by the median value.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "data  = data.dropna(subset=['RoofSurface'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `ChimneyStyle`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Questions** about `ChimneyStyle` ‚ùì\n",
    "\n",
    "Investigate the missing values in `ChimneyStyle`. Then, choose one of the following solutions:\n",
    "\n",
    "1. Drop the column entirely\n",
    "2. Impute the column median\n",
    "3. Preserve the NaNs and replace them with meaningful values\n",
    "\n",
    "Make changes effective in the dataframe `data`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>üí° <i>Hint</i></summary>\n",
    "    \n",
    "* ‚ö†Ô∏è Be careful: not all missing values are represented as `np.nans`, and Python's `isnull()` only detects `np.nans`...\n",
    "    \n",
    "* ‚ÑπÔ∏è `ChimneyStyle` has a lot of missing values. The description does not touch on what they represent. As such, it is better not to make any assumptions and to drop the column entirely.\n",
    "    \n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1683/3989418296.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.drop(columns='ChimneyStyle', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "data.drop(columns='ChimneyStyle', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üß™ **Test your code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.10.6, pytest-7.1.3, pluggy-1.0.0 -- /home/ricorenzo/.pyenv/versions/lewagon/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/ricorenzo/code/renzorico/data-preprocessing-workflow/tests\n",
      "plugins: asyncio-0.19.0, anyio-3.6.2\n",
      "asyncio: mode=strict\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 2 items\n",
      "\n",
      "test_missing_values.py::TestMissing_values::test_nans \u001b[32mPASSED\u001b[0m\u001b[32m             [ 50%]\u001b[0m\n",
      "test_missing_values.py::TestMissing_values::test_number_of_columns \u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m2 passed\u001b[0m\u001b[32m in 0.30s\u001b[0m\u001b[32m ===============================\u001b[0m\n",
      "\n",
      "\n",
      "üíØ You can commit your code:\n",
      "\n",
      "\u001b[1;32mgit\u001b[39m add tests/missing_values.pickle\n",
      "\n",
      "\u001b[32mgit\u001b[39m commit -m \u001b[33m'Completed missing_values step'\u001b[39m\n",
      "\n",
      "\u001b[32mgit\u001b[39m push origin master\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('missing_values',\n",
    "                         dataset = data\n",
    ")\n",
    "\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master 0165347] Completed missing_values step\n",
      " 1 file changed, 0 insertions(+), 0 deletions(-)\n",
      "ERROR: Repository not found.\n",
      "fatal: Could not read from remote repository.\n",
      "\n",
      "Please make sure you have the correct access rights\n",
      "and the repository exists.\n"
     ]
    }
   ],
   "source": [
    "!git add .\n",
    "\n",
    "!git commit -m 'Completed missing_values step'\n",
    "\n",
    "!git push origin master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì When you are done with handling missing value, print out the percentage of missing values for the entire dataframe ‚ùì\n",
    "\n",
    "You should no longer have missing values !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GrLivArea       0.0\n",
       "BedroomAbvGr    0.0\n",
       "KitchenAbvGr    0.0\n",
       "OverallCond     0.0\n",
       "RoofSurface     0.0\n",
       "GarageFinish    0.0\n",
       "CentralAir      0.0\n",
       "MoSold          0.0\n",
       "SalePrice       0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "missing_values = data.isnull().sum().sort_values()/len(data)\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First of all, before scaling...**\n",
    "\n",
    "To understand the effects of scaling and encoding on model performance, let's get a **base score without any data transformation**.\n",
    "\n",
    "‚ùì Cross-validate a linear regression model that predicts `SalePrice` using the other features ‚ùì\n",
    "\n",
    "‚ö†Ô∏è Note that a linear regression model can only handle numeric features. [DataFrame.select_dtypes](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.select_dtypes.html) can help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep this score in mind! You will train a new model after data preprocessing in Challenge #2 - see if it improves your average score üòâ\n",
    "\n",
    "üöÄ Now, back to **feature scaling**!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  `RoofSurface` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question** about `RoofSurface` ‚ùì\n",
    "\n",
    "üëá Investigate `RoofSurface` for distribution and outliers. Then, choose the most appropriate scaling technique. Either:\n",
    "\n",
    "1. Standard Scaler\n",
    "2. Robust Scaler\n",
    "3. MinMax Scaler\n",
    "\n",
    "Replace the original columns with the transformed values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>üí° <i>Hint</i></summary>\n",
    "    \n",
    "‚ÑπÔ∏è Since `RoofSurface` has neither a Gaussian distribution, nor outliers $\\rightarrow$ MinMaxScaler.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `GrLivArea`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question** about `GrLivArea` ‚ùì\n",
    "\n",
    "üëá Investigate `GrLivArea` for distribution and outliers. Then, choose the most appropriate scaling technique. Either:\n",
    "\n",
    "1. Standard Scaler\n",
    "2. Robust Scaler\n",
    "3. MinMax Scaler\n",
    "\n",
    "Replace the original columns with the transformed values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>üí° <i>Hint</i></summary>\n",
    "    \n",
    "‚ÑπÔ∏è `GrLivArea` has many outliers $\\rightarrow$ RobustScaler()\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `BedroomAbvGr` ,  `OverallCond` & `KitchenAbvGr`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Questions** about `BedroomAbvGr`, `OverallCond` & `KitchenAbvGr` ‚ùì\n",
    "\n",
    "üëá Investigate `BedroomAbvGr`, `OverallCond` & `KitchenAbvGr`. Then, chose one of the following scaling techniques:\n",
    "\n",
    "1. MinMax Scaler\n",
    "2. Standard Scaler\n",
    "3. Robust Scaler\n",
    "\n",
    "Replace the original columns with the transformed values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>üí° <i>Hint</i></summary>\n",
    "    \n",
    "‚ÑπÔ∏è `BedroomAbvGr` ,  `OverallCond` & `KitchenAbvGr` are ordinal features. There are less than 0.1% of outliers so no need to use _RobustScaler()_. The distribution is not Gaussian, hence no _StandardScaler()_. By elimination, you can confidently choose _MinMaxScaler()_.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üß™ **Test your code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('scaling',\n",
    "                         dataset = data\n",
    ")\n",
    "\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) Feature Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `GarageFinish`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question** about `GarageFinish`‚ùì\n",
    "\n",
    "üëá Investigate `GarageFinish` and choose one of the following encoding techniques accordingly:\n",
    "- Ordinal encoding\n",
    "- One-Hot encoding\n",
    "\n",
    "Add the encoding to the dataframe as new colum(s), and remove the original column.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>üí° <i>Hint</i></summary>\n",
    "        \n",
    "‚ÑπÔ∏è `GarageFinish` is a multicategorical feature that should be One-hot-encoded. You could also consider an Ordinal Encoding but we would have to know for sure that Unfinished or no garage are definitely worse that rough finished!\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GarageFinish_ohe.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding  `CentralAir`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question** about `CentralAir`‚ùì\n",
    "\n",
    "Investigate `CentralAir` and choose one of the following encoding techniques accordingly:\n",
    "- Ordinal encoding\n",
    "- One-Hot encoding\n",
    "\n",
    "Replace the original column with the newly generated encoded columns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>üí° <i>Hint</i></summary>\n",
    "    \n",
    "‚ÑπÔ∏è `CentralAir` is a binary categorical feature.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (5) Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `MoSold` - Cyclical engineering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üë®üèª‚Äçüè´ A feature can be numerical (continuous or discrete), categorical or ordinal. But a feature can also be temporal (e.g. quarters, months, days, minutes, ...). \n",
    "\n",
    "Cyclical features like time need some specific preprocessing. Indeed, if you want any Machine Learning algorithm to capture this cyclicity, your cyclical features must be preprocessed in a certain way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ Consider the feature `MoSold`, the month on which the house was sold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"MoSold\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Many houses were sold in June (6), July (7) and May (5) (Spring/Summer)\n",
    "* Only a few houses were sold in December (12), January (1) and February (2) (~ Fall/Winter)\n",
    "    * But for any Machine Learning model, there is no reason why December (12) and January (1) would be \"close\"..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üë©üèª‚Äçüè´ ***How to deal with cyclical features?***\n",
    "\n",
    "1.  Look at the following illustration and read the explanations to distinguish two different months.\n",
    "\n",
    "<img src=\"https://wagon-public-datasets.s3.amazonaws.com/05-Machine-Learning/02-Prepare-the-dataset/cyclical_feature_engineering.png\" alt=\"Cyclical features\" width=\"1000\">\n",
    "\n",
    "\n",
    "2. Read this [article](https://ianlondon.github.io/blog/encoding-cyclical-features-24hour-time/) for more details.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question** about `MoSold` ‚ùì \n",
    "- Create two new features `sin_MoSold` and `cos_MoSold` which correspond respectively to the sine and cosine of MoSold.\n",
    "- Drop the original column `MoSold`\n",
    "\n",
    "<details>\n",
    "    <summary>üí° <i>Hint</i></summary>\n",
    "    \n",
    "To create a time engineered feature based on a column which gives the second in the day!\n",
    "```python\n",
    "seconds_in_day = 24*60*60\n",
    "\n",
    "df['sin_time'] = np.sin(2*np.pi*df.seconds/seconds_in_day)\n",
    "df['cos_time'] = np.cos(2*np.pi*df.seconds/seconds_in_day)\n",
    "df.drop(columns=['seconds'], inplace=True)\n",
    "\n",
    "df.head()\n",
    "```\n",
    "\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üß™ **Test your code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('encoding', dataset = data, new_features = ['sin_MoSold', 'cos_MoSold'])\n",
    "\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (6) Export the preprocessed dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëá Now that the dataset has been preprocessed, execute the code below to export it. You will keep working on it in the next exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"data/clean_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üèÅ Congratulations! Now, you know how to ***preprocess a dataset*** !\n",
    "\n",
    "üíæ Don't forget to git add/commit/push your notebook...\n",
    "\n",
    "üöÄ ... and move on to the next challenge!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
